{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from itertools import cycle\n",
    "import matplotlib.patches as mpatches \n",
    "import random\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from utils.Utilities import Utilities\n",
    "from utils.EEGDataset import EEGDataset\n",
    "from utils.Caltech101Dataset import Caltech101Dataset\n",
    "\n",
    "Utilities_handler = Utilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "resnet50_model = resnet50(weights=weights)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "# Remove the final classification (softmax) layer\n",
    "model = torch.nn.Sequential(*(list(resnet50_model.children())[:-1])) \n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT =1\n",
    "BATCH_SIZE = 1\n",
    "learning_rate = 0.01\n",
    "EPOCHS = 100\n",
    "SaveModelOnEveryEPOCH = 100\n",
    "EEG_DATASET_PATH = \"./data/eeg/eeg_signals_raw_with_mean_std.pth\"\n",
    "# EEG_DATASET_PATH = \"./data/eeg/eeg_55_95_std.pthh\"\n",
    "\n",
    "LSTM_INPUT_FEATURES = 2048 # should be image features output.\n",
    "LSTM_HIDDEN_SIZE = 460  # should be same as sequence length\n",
    "\n",
    "# custom_model_weights =  \"./models/raw/FC__subject1_epoch_10.pth\"\n",
    "# custom_model_weights =  \"./models/raw/FC__subject1_epoch_49.pth\"\n",
    "# custom_model_weights =  \"./models/raw/50/subject1/FC__subject1_epoch_10.pth\"\n",
    "# custom_model_weights =  \"./models/raw/mse50/FC__subject1_epoch_20.pth\"\n",
    "# custom_model_weights =  \"./models/raw/FC__subject1_epoch_199.pth\"\n",
    "\n",
    "custom_model_weights =  \"./logs/1/VIT_Head_finetuned_eeg_subject_1_epoch40.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded custom weights: ./logs/1/VIT_Head_finetuned_eeg_subject_1_epoch40.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=2000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2000, out_features=2000, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=2000, out_features=58880, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.CustomModel import CustomModel\n",
    "CustModel = CustomModel(input_size=(LSTM_INPUT_FEATURES),output_size=(LSTM_HIDDEN_SIZE*128))\n",
    "\n",
    "if os.path.exists(custom_model_weights):\n",
    "    CustModel = torch.load(custom_model_weights)\n",
    "    print(f\"loaded custom weights: {custom_model_weights}\")\n",
    "\n",
    "CustModel = CustModel.to(device)\n",
    "CustModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9144/9144 [00:00<00:00, 380944.36it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = EEGDataset(subset=\"train\",eeg_signals_path=EEG_DATASET_PATH, eeg_splits_path=\"./data/eeg/block_splits_by_image_all.pth\", subject=1,preprocessin_fn=weights.transforms(), time_low=20, time_high=480)\n",
    "test_dataset = Caltech101Dataset(images_path=\"./data/images/caltech/101_ObjectCategories\",preprocessin_fn=weights.transforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech_label_wise_data = {}\n",
    "\n",
    "if os.path.exists(\"./preProcessedData/caltech101_preProcessed_eegPredicted_labelWise_49_epochs.pth\"):\n",
    "    caltech_label_wise_data = torch.load(\"./preProcessedData/caltech101_preProcessed_eegPredicted_labelWise_49_epochs.pth\")\n",
    "    print(\"loaded:./preProcessedData/caltech101_preProcessed_eegPredicted_labelWise_49_epochs.pth\")\n",
    "else:\n",
    "    caltech_label_wise_data = Utilities_handler.load_data_label_wise(test_dataset,model=model,CustModel=CustModel,device=device,process_data_with_model=True)\n",
    "# for data in test_dataset:\n",
    "#     _, label, image,i = data\n",
    "#     with torch.no_grad():\n",
    "#         features = model(image.unsqueeze(0).to(device))\n",
    "#         features = features.view(-1, features.size(1))\n",
    "#         outputs = CustModel(features)\n",
    "#     test_eeg = outputs.cpu().numpy() \n",
    "#     if not label[\"ClassId\"] in caltech_label_wise_data:\n",
    "#         caltech_label_wise_data[label[\"ClassId\"]] = {\"images\":[], \"eeg\":[], \"pred_eeg\":[]}\n",
    "#     caltech_label_wise_data[label[\"ClassId\"]][\"images\"].append(image)\n",
    "#     caltech_label_wise_data[label[\"ClassId\"]][\"pred_eeg\"].append(test_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech_label_wise_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(caltech_label_wise_data, \"./preProcessedData/caltech101_preProcessed_eegPredicted_labelWise_49_epochs.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareEEGData(labelWiseData, convert_to_numpy=True, flatten_eeg=True):\n",
    "    eeg_features_ = []\n",
    "    eeg_labels_ = []\n",
    "    for label, labeData in labelWiseData.items():\n",
    "        pred_eeg_fet = labeData[\"pred_eeg\"]\n",
    "        for idx,eeg in enumerate(pred_eeg_fet):\n",
    "            eeg_features_.append(pred_eeg_fet[idx][0])\n",
    "            eeg_labels_.append(label)\n",
    "    if convert_to_numpy:\n",
    "        eeg_features_  =np.array(eeg_features_, dtype=float)\n",
    "    if flatten_eeg:\n",
    "        eeg_features_ = eeg_features_.reshape(eeg_features_.shape[0], -1) \n",
    "    return eeg_features_, eeg_labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech_eeg_pred_features = []\n",
    "caltech_eeg_labels = []\n",
    "# for label, labeData in caltech_label_wise_data.items():\n",
    "#     pred_eeg_fet = labeData[\"pred_eeg\"]\n",
    "#     for idx,eeg in enumerate(pred_eeg_fet):\n",
    "#         caltech_eeg_pred_features.append(pred_eeg_fet[idx][0])\n",
    "#         caltech_eeg_labels.append(label)\n",
    "# caltech_eeg_pred_features  =np.array(caltech_eeg_pred_features, dtype=float)\n",
    "# caltech_eeg_pred_features = caltech_eeg_pred_features.reshape(caltech_eeg_pred_features.shape[0], -1)\n",
    "caltech_eeg_pred_features,caltech_eeg_labels = prepareEEGData(caltech_label_wise_data, convert_to_numpy=True, flatten_eeg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save((caltech_eeg_pred_features,caltech_eeg_labels), \"./preProcessedData/caltech101_preProcessed_eegfeatures_labels.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caltech_eeg_pred_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne_flattned_preds_caltech = TSNE(n_components=3,perplexity=40, init=\"pca\", learning_rate=0.1, n_iter=1000).fit_transform(caltech_eeg_pred_features)\n",
    "# torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().set_size_inches(20,10)\n",
    "plt.clf()\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"tab20c\", int(1*len(caltech_label_wise_data.keys())))\n",
    "cmap_pred = plt.cm.get_cmap(\"tab20c\", int(1*len(caltech_label_wise_data.keys())))\n",
    "\n",
    "gen_colors = []\n",
    "handles = []\n",
    "cmaps = []\n",
    "\n",
    "gen_colors_pred = []\n",
    "handles_pred = []\n",
    "cmaps_pred = []\n",
    "\n",
    "for eeg_label in list(caltech_label_wise_data.keys()):\n",
    "    \n",
    "    cmaps.append(cmap(eeg_label))\n",
    "    cmaps_pred.append(cmap_pred(eeg_label))\n",
    "    # if eeg_label==0 or eeg_label==15 or eeg_label==30:\n",
    "    _patch = mpatches.Patch(color=cmap(eeg_label), label=f'Class {eeg_label}') \n",
    "    handles.append(_patch)\n",
    "    _patch = mpatches.Patch(color=cmap_pred(eeg_label), label=f'Class {eeg_label} Pred') \n",
    "    handles_pred.append(_patch)\n",
    "\n",
    "\n",
    "for i in range(caltech_eeg_pred_features.shape[0]):\n",
    "    colorMap = cmaps[caltech_eeg_labels[i]]\n",
    "    gen_colors.append(colorMap)\n",
    "\n",
    "    colorMap = cmaps_pred[caltech_eeg_labels[i]]\n",
    "    gen_colors_pred.append(colorMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(25, 25))\n",
    "fig.set_size_inches(25,25)\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "fig.add_axes(ax)\n",
    "\n",
    "ax.set_title(\"EEG data\")\n",
    "# ax.view_init(azim=90, elev=1)\n",
    "ax.view_init(azim=60, elev=5)\n",
    "_ = ax.text2D(0.0, 1.0, s=f\"n_samples={X_tsne_flattned_preds_caltech.shape[0]}\", transform=ax.transAxes)\n",
    "\n",
    "sel_channel = 97\n",
    "ax.scatter(X_tsne_flattned_preds_caltech[:,0],X_tsne_flattned_preds_caltech[:,1],X_tsne_flattned_preds_caltech[:,2], c=gen_colors_pred, s=30, alpha=0.8)\n",
    "ax.legend(handles=handles_pred, loc=\"best\", fontsize=13,fancybox=True,ncol=10)\n",
    "fig.savefig(\"Caltech_Predicted_EEG_Map.png\",bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_wise_data = {}\n",
    "model.eval()\n",
    "CustModel.eval()\n",
    "# label_wise_data = Utilities_handler.load_data_label_wise(dataset=dataset,model=model,CustModel=CustModel,device=device,process_data_with_model=True)\n",
    "\n",
    "for data in dataset:\n",
    "    eeg, label, image,i = data\n",
    "    with torch.no_grad():\n",
    "        features = model(image.unsqueeze(0).to(device))\n",
    "        features = features.view(-1, features.size(1))\n",
    "        outputs = CustModel(features)\n",
    "    test_eeg = outputs.cpu().numpy() \n",
    "\n",
    "    if not label[\"ClassId\"] in label_wise_data:\n",
    "        label_wise_data[label[\"ClassId\"]] = {\"images\":[], \"eeg\":[], \"pred_eeg\":[]}\n",
    "\n",
    "    label_wise_data[label[\"ClassId\"]][\"images\"].append(image)\n",
    "    label_wise_data[label[\"ClassId\"]][\"pred_eeg\"].append(test_eeg)\n",
    "    label_wise_data[label[\"ClassId\"]][\"eeg\"].append(eeg.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_wise_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_features = []\n",
    "eeg_pred_features = []\n",
    "eeg_labels = []\n",
    "for label, labeData in label_wise_data.items():\n",
    "    eeg_fet = labeData[\"eeg\"]\n",
    "    pred_eeg_fet = labeData[\"pred_eeg\"]\n",
    "    for idx,eeg in enumerate(eeg_fet):\n",
    "        # if not label==32 and not label==6:\n",
    "            eeg_features.append(eeg)\n",
    "            eeg_pred_features.append(pred_eeg_fet[idx][0])\n",
    "            eeg_labels.append(label)\n",
    "# for labeData in label_wise_data[0][\"eeg\"]:\n",
    "#     eeg_features.append(labeData)\n",
    "eeg_features  =np.array(eeg_features, dtype=float)\n",
    "eeg_pred_features  =np.array(eeg_pred_features, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eeg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelMap = Utilities_handler.read_channel_map(input_file=\"./channelmap.txt\")\n",
    "channel_names = list(channelMap.values())  # Add more channel names as needed\n",
    "channel_types = ['eeg'] * len(channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_features = eeg_features.reshape(eeg_features.shape[0], -1)\n",
    "# noiseless_eeg = noiseless_eeg.reshape(noiseless_eeg.shape[0], -1)\n",
    "# samples, time_length , channels  = denoised_ICA_EEG.shape\n",
    "# denoised_ICA_EEG = denoised_ICA_EEG.reshape(samples, channels, time_length)\n",
    "# denoised_ICA_EEG = denoised_ICA_EEG.reshape(samples, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_features.shape, eeg_pred_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = []\n",
    "for channe in range(128):\n",
    "    if \"O\" in channelMap[channe+1]:\n",
    "        # print(channe,channel_map[channe+1])\n",
    "        selected_channels.append(channe)\n",
    "\n",
    "# selected_channels.remove(27)  # 27 PO9\n",
    "# selected_channels.remove(28)  # 28 O1\n",
    "# selected_channels.remove(29)  # 29 Oz\n",
    "# selected_channels.remove(30)  # 30 O2\n",
    "# selected_channels.remove(31)  # 31 PO10\n",
    "# selected_channels.remove(59)  # 59 PO7\n",
    "# selected_channels.remove(60)  # 60 PO3\n",
    "# selected_channels.remove(61)  # 61 POz\n",
    "# selected_channels.remove(62)  # 62 PO4\n",
    "# selected_channels.remove(63)  # 63 PO8\n",
    "# selected_channels.remove(91)  # 91 POO9h\n",
    "# selected_channels.remove(92)  # 92 POO1\n",
    "# selected_channels.remove(93)  # 93 POO2\n",
    "# selected_channels.remove(94)  # 94 POO10h\n",
    "# selected_channels.remove(117) # 117 PPO9h\n",
    "# selected_channels.remove(118) # 118 PPO5h\n",
    "# selected_channels.remove(119) # 119 PPO1h\n",
    "# selected_channels.remove(120) # 120 PPO2h\n",
    "# selected_channels.remove(121) # 121 PPO6h\n",
    "# selected_channels.remove(122) # 122 PPO10h\n",
    "# selected_channels.remove(125) # 125 OI1h\n",
    "# selected_channels.remove(126) # 126 OI2h\n",
    "\n",
    "for chn in selected_channels:\n",
    "    print(f\"Channel : {chn}-{channelMap[chn+1]} will be displayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne_flattned_imagenet = TSNE(n_components=3,perplexity=40, init=\"pca\", learning_rate=0.1, n_iter=1000).fit_transform(eeg_features)\n",
    "# torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")\n",
    "\n",
    "X_tsne_flattned_preds_imagenet = TSNE(n_components=3,perplexity=40, init=\"pca\", learning_rate=0.1, n_iter=1000).fit_transform(eeg_pred_features)\n",
    "# torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")\n",
    "\n",
    "# X_tsne_flattned_preds = TSNE(n_components=3,perplexity=40, init=\"pca\", learning_rate=0.1, n_iter=500).fit_transform(caltech_eeg_pred_features)\n",
    "# # torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().set_size_inches(20,10)\n",
    "plt.clf()\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"Set1\", int(1*len(label_wise_data.keys())))\n",
    "cmap_pred = plt.cm.get_cmap(\"tab20c\", int(1*len(label_wise_data.keys())))\n",
    "\n",
    "gen_colors_imagenet = []\n",
    "handles_imagenet = []\n",
    "cmaps_imagenet = []\n",
    "\n",
    "gen_colors_pred_imagenet = []\n",
    "handles_pred_imagenet = []\n",
    "cmaps_pred_imagenet = []\n",
    "\n",
    "for eeg_label in list(label_wise_data.keys()):\n",
    "    \n",
    "    cmaps_imagenet.append(cmap(eeg_label))\n",
    "    cmaps_pred_imagenet.append(cmap_pred(eeg_label))\n",
    "    # if eeg_label==0 or eeg_label==15 or eeg_label==30:\n",
    "    _patch = mpatches.Patch(color=cmap(eeg_label), label=f'Class {eeg_label}') \n",
    "    handles_imagenet.append(_patch)\n",
    "    _patch = mpatches.Patch(color=cmap_pred(eeg_label), label=f'Class {eeg_label} Pred') \n",
    "    handles_pred_imagenet.append(_patch)\n",
    "\n",
    "\n",
    "for i in range(eeg_features.shape[0]):\n",
    "    colorMap = cmaps_imagenet[eeg_labels[i]]\n",
    "    gen_colors_imagenet.append(colorMap)\n",
    "\n",
    "    colorMap = cmaps_pred_imagenet[eeg_labels[i]]\n",
    "    gen_colors_pred_imagenet.append(colorMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_cmaps = []\n",
    "channel_cmap = plt.cm.get_cmap(\"hsv\", 128)\n",
    "for chn_range in range(128):\n",
    "    channel_cmaps.append(channel_cmap(chn_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tsne_flattned = TSNE(n_components=3,perplexity=40, init=\"pca\", learning_rate=0.1, n_iter=1000).fit_transform(eeg_features)\n",
    "# torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")\n",
    "\n",
    "# X_tsne_flattned_preds = TSNE(n_components=3,perplexity=40, init=\"pca\",  learning_rate=0.1, n_iter=1000).fit_transform(eeg_pred_features)\n",
    "# torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X_tsne_flattned_preds_imagenet[:,0], X_tsne_flattned_preds_imagenet[:,1], c=gen_colors_pred_imagenet, alpha=0.5)\n",
    "# plt.scatter(X_tsne_flattned_imagenet[:,0], X_tsne_flattned_imagenet[:,1], c=gen_colors_imagenet, alpha=0.5)\n",
    "# plt.plot([X_tsne_flattned_preds[:,0],X_tsne_flattned[:,0]],[X_tsne_flattned_preds[:,1],X_tsne_flattned[:,1]], c=\"blue\", lw=0.5)\n",
    "plt.legend(handles=handles_pred_imagenet, loc=\"lower right\", fontsize=13, bbox_to_anchor=(2.2, 0.1),fancybox=True,ncol=5)\n",
    "# plt.savefig(\"test_train_preds_fc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tsne_flattned = TSNE(n_components=3,perplexity=30, init=\"pca\", learning_rate=0.1, n_iter=500, angle=0.5).fit_transform(eeg_features)\n",
    "# torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")\n",
    "\n",
    "# X_tsne_flattned_preds = TSNE(n_components=3,perplexity=20, init=\"pca\",  learning_rate=0.1, n_iter=1000).fit_transform(eeg_pred_features)\n",
    "# torch.save(X_tsne_flattned,\"tsne_fltattned_raw_data_perplexity_20_init_random_lr_auto.pth\")\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.set_size_inches(20,20)\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "fig.add_axes(ax)\n",
    "\n",
    "ax.set_title(\"EEG data\")\n",
    "# ax.view_init(azim=90, elev=1)\n",
    "ax.view_init(azim=60, elev=90)\n",
    "_ = ax.text2D(0.0, 1.0, s=\"n_samples=1500\", transform=ax.transAxes)\n",
    "\n",
    "\n",
    "ax.scatter(X_tsne_flattned_preds_imagenet[:,0], X_tsne_flattned_preds_imagenet[:,1], X_tsne_flattned_preds_imagenet[:,2], c=gen_colors_pred_imagenet, s=30, alpha=0.8)\n",
    "# ax.legend(handles=handles_pred_imagenet, loc=\"best\", fontsize=13,fancybox=True,ncol=7)\n",
    "\n",
    "# ax.scatter(X_tsne_flattned_imagenet[:,0], X_tsne_flattned_imagenet[:,1], X_tsne_flattned_imagenet[:,2], c=gen_colors_imagenet, s=30, alpha=0.8)\n",
    "# ax.legend(handles=hanttned_imagenet[:,0], X_tsne_flattned_imagenet[:,1], X_tsne_flattned_imagenet[:,2], c=gen_colors_imagenet, s=30, alpha=0.8)\n",
    "# ax.legend(handles=handles_imagenet, loc=\"best\", fontsize=13,fancybox=True,ncol=7)\n",
    "\n",
    "# ax.legend(handles=handles_imagenet+handles_pred_imagenet, loc=\"best\", fontsize=13,fancybox=True,ncol=7)\n",
    "\n",
    "# ax.scatter(X_tsne_flattned_preds_caltech[:,0],X_tsne_flattned_preds_caltech[:,1],X_tsne_flattned_preds_caltech[:,2], c=gen_colors_pred, s=30, alpha=0.8)\n",
    "# ax.legend(handles=handles_pred, loc=\"best\", fontsize=13,fancybox=True,ncol=10)\n",
    "\n",
    "# ax.scatter(X_tsne_flattned_preds[:,0],X_tsne_flattned_preds[:,1],X_tsne_flattned_preds[:,2], c=gen_colors, s=30, alpha=0.8)\n",
    "# ax.legend(handles=handles_imagenet+handles_pred_imagenet, loc=\"best\", fontsize=13,fancybox=True,ncol=10)\n",
    "ax.legend(handles=handles_pred_imagenet, loc=\"best\", fontsize=13,fancybox=True,ncol=7)\n",
    "# \n",
    "# fig.savefig(\"Imagenet_Map_Pred_EEGs_50epochs.png\",bbox_inches='tight')\n",
    "# fig.savefig(\"Imagenet_Map_Raw_EEGs_50epochs.png\",bbox_inches='tight')\n",
    "# fig.savefig(\"Imagenet_Map_Raw_and_Pred_EEGs_50epochs.png\",bbox_inches='tight')\n",
    "# fig.savefig(\"Imagenet_Map_Raw_EEGs_Caltech_Data_50epochs.png\",bbox_inches='tight')\n",
    "\n",
    "\n",
    "# fig.savefig(\"Imagenet_Map_Pred_EEGs_Caltech_Data_50epochs.png\",bbox_inches='tight')\n",
    "\n",
    "# fig.savefig(\"Imagenet_Map_Pred_RAW_EEGs_20epochs.png\",bbox_inches='tight')\n",
    "# fig.savefig(\"Imagenet_Map_Pred_EEGs_20epochs.png\",bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_labels_np = np.array(eeg_labels)\n",
    "print(eeg_labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = np.where(eeg_labels_np == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.take(tsne_channel_wise[0], filtered, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label_idx, c_label in enumerate(list(set(eeg_labels))):\n",
    "c_label = 0\n",
    "for chn in range(128):\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    fig.set_size_inches(20,20)\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    fig.add_axes(ax)\n",
    "\n",
    "    ax.set_title(\"EEG data\")\n",
    "    ax.view_init(azim=-50, elev=50)\n",
    "    _ = ax.text2D(0.8, 0.05, s=\"n_samples=1500\", transform=ax.transAxes)\n",
    "\n",
    "    handles.append(mpatches.Patch(color=channel_cmaps[int(random.random()*128)], label=f'Channel {chn}') )\n",
    "    plt.legend(handles=handles, loc=\"lower right\", fontsize=10,ncol=4, bbox_to_anchor=(1.0, 0.0),fancybox=True) \n",
    "\n",
    "    # filtered = np.where(eeg_labels_np == c_label)[0]\n",
    "    # filtered_tsne = np.take(tsne_channel_wise[chn], filtered, 0)\n",
    "    # ax.scatter(filtered_tsne[:,0], filtered_tsne[:,1], c=[cmaps[c_label] for i in range(filtered_tsne.shape[0])], s=50, alpha=0.8)\n",
    "    ax.scatter(tsne_channel_wise[chn][:,0], tsne_channel_wise[chn][:,1],tsne_channel_wise[chn][:,2], c=gen_colors, s=50, alpha=0.8)\n",
    "    \n",
    "    fig.savefig(f\"output/{c_label}_raw_eeg_channel_{chn}.png\")\n",
    "    fig.clf()\n",
    "\n",
    "    del handles[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EEG flattened features fit.\n",
    "# X_tsne = TSNE(n_components=3,perplexity=50, init=\"pca\", learning_rate='auto').fit_transform(eeg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=gen_colors,cmap=plt.get_cmap(\"Spectral\"),alpha=.4,edgecolor='k',projection=\"3d\")\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "fig.add_axes(ax)\n",
    "ax.scatter(\n",
    "    X_tsne[:, 0], X_tsne[:, 1], c=gen_colors, s=50, alpha=0.8\n",
    ")\n",
    "ax.set_title(\"EEG data\")\n",
    "ax.view_init(azim=-66, elev=12)\n",
    "_ = ax.text2D(0.8, 0.05, s=\"n_samples=1500\", transform=ax.transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_SAMPLE = 0\n",
    "SELECTED_CLASS = 13\n",
    "SELECTED_CHANNEL = 1\n",
    "TIME_SERIES_START = 0\n",
    "TIEM_SERIES_END = 500\n",
    "\n",
    "SELECTED_CLASSES = [2,13,19,25,30]\n",
    "\n",
    "\n",
    "colorMapString = {}\n",
    "\n",
    "for SELECTED_CLASS in SELECTED_CLASSES:\n",
    "\n",
    "    label0data = np.array(label_wise_data[SELECTED_CLASS][\"eeg\"])\n",
    "    cmap = plt.cm.get_cmap(\"tab20\", label0data.shape[0])\n",
    "\n",
    "    for sample_num in range(10):\n",
    "\n",
    "        plt.figure().set_size_inches(20,10)\n",
    "        plt.clf()\n",
    "        f, axarr = plt.subplots(1,2)\n",
    "        f.set_size_inches(20,10)\n",
    "\n",
    "        handles = []\n",
    "        \n",
    "        SELECTED_SAMPLE = sample_num\n",
    "\n",
    "        image = label_wise_data[SELECTED_CLASS][\"images\"][SELECTED_SAMPLE]\n",
    "        for channe_num in selected_channels:\n",
    "            rand_int = random.randint(0, label0data.shape[0])\n",
    "            colorMap = cmap(rand_int)\n",
    "            if not channel_map[channe_num+1] in colorMapString:\n",
    "                colorMapString[channel_map[channe_num+1]] = colorMap\n",
    "\n",
    "            colorMap = colorMapString[channel_map[channe_num+1]]\n",
    "\n",
    "            axarr[1].plot(label0data[SELECTED_SAMPLE][TIME_SERIES_START:TIEM_SERIES_END,channe_num], c=colorMap)\n",
    "            max_of_channel  =np.max(label0data[SELECTED_SAMPLE][TIME_SERIES_START:TIEM_SERIES_END,channe_num])\n",
    "            max_of_channel = str(np.round(max_of_channel,2))\n",
    "            min_of_channel  = np.min(label0data[SELECTED_SAMPLE][TIME_SERIES_START:TIEM_SERIES_END,channe_num])\n",
    "            min_of_channel = str(np.round(min_of_channel,2))\n",
    "            _channel_patch = mpatches.Patch(color=colorMap, label=f'Channel: {channe_num}:{channel_map[channe_num+1]} [{min_of_channel}:{max_of_channel}]')\n",
    "            handles.append(_channel_patch)\n",
    "\n",
    "        rand_int = random.randint(1, label0data.shape[0])\n",
    "        _sample_patch = mpatches.Patch(color=cmap(rand_int), label=f'Sample: {SELECTED_SAMPLE}')\n",
    "        handles.append(_sample_patch)\n",
    "\n",
    "        if not f\"class_{SELECTED_CLASS}\" in colorMapString:\n",
    "            rand_int = random.randint(1, label0data.shape[0])\n",
    "            colorMap = cmap(rand_int)\n",
    "            colorMapString[f\"class_{SELECTED_CLASS}\"] = colorMap\n",
    "\n",
    "        _class_patch = mpatches.Patch(color=colorMapString[f\"class_{SELECTED_CLASS}\"], label=f\"CLASS: {SELECTED_CLASS}\")\n",
    "        handles.append(_class_patch)\n",
    "\n",
    "        if not \"TS\" in colorMapString:\n",
    "            rand_int = random.randint(1, label0data.shape[0])\n",
    "            colorMap = cmap(rand_int)\n",
    "            colorMapString[\"TS\"] = colorMap\n",
    "\n",
    "        TS_patch = mpatches.Patch(color=colorMapString[\"TS\"],label=f\"T: {TIME_SERIES_START}:{TIEM_SERIES_END}\") \n",
    "        handles.append(TS_patch)\n",
    "\n",
    "        axarr[1].legend(handles=handles, loc=\"lower right\", fontsize=13, bbox_to_anchor=(1.0, 0.0),fancybox=True,ncol=1)\n",
    "        axarr[0].imshow(image)\n",
    "        f.savefig(f\"./output/Class_{SELECTED_CLASS}_Sample_{SELECTED_SAMPLE}_Channels_{selected_channels}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
